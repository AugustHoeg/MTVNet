import argparse
import os

import cv2
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
from PIL import Image

from SaliencyModel.BackProp import GaussianBlurPath, GaussianBlurPath_2d
from SaliencyModel.BackProp import attribution_objective, Path_gradient, Path_gradient_ArSSR, make_coord
from SaliencyModel.BackProp import attribution_objective_2d, Path_gradient_2d
from SaliencyModel.BackProp import saliency_map_PG as saliency_map
from SaliencyModel.attributes import attr_grad, attr_grad_2d
from SaliencyModel.utils import cv2_to_pil, pil_to_cv2, gini
from SaliencyModel.utils import vis_saliency, grad_abs_norm, grad_abs_norm_2d

import config
from utils.load_options import load_json, load_options_from_experiment_id


def parse_options(options_file=None):

    # Load default experiment option from config.py
    if config.MODEL_ARCHITECTURE == "mDCSRN_GAN":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_mDCSRN_GAN.json')
    elif config.MODEL_ARCHITECTURE == "mDCSRN":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_mDCSRN.json')
    elif config.MODEL_ARCHITECTURE == "SuperFormer":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_SuperFormer.json')
    elif config.MODEL_ARCHITECTURE == "ESRGAN3D":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_ESRGAN3D.json')
    elif config.MODEL_ARCHITECTURE == "RRDBNet3D":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_RRDBNet3D.json')
    elif config.MODEL_ARCHITECTURE == "EDDSR":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_EDDSR.json')
    elif config.MODEL_ARCHITECTURE == "MFER":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_MFER.json')
    elif config.MODEL_ARCHITECTURE == "MTVNet":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_MTVNet.json')
    elif config.MODEL_ARCHITECTURE == "ArSSR":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_ArSSR.json')
    elif config.MODEL_ARCHITECTURE == "RCAN":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_RCAN.json')
    elif config.MODEL_ARCHITECTURE == "SwinIR":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_SwinIR.json')
    elif config.MODEL_ARCHITECTURE == "HAT":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_HAT.json')
    elif config.MODEL_ARCHITECTURE == "DRCT":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_DRCT.json')
    elif config.MODEL_ARCHITECTURE == "DUMMY":
        opt_path = os.path.join(config.ROOT_DIR, 'options', 'train_DUMMY.json')
    else:
        raise NotImplementedError('Model architecture %s not implemented.' % config.MODEL_ARCHITECTURE)

    # Load options
    opt = load_json(opt_path)

    return opt

def parse_LAM_arguments():
    # Parse command-line arguments for LAM analysis
    parser = argparse.ArgumentParser(description="Run LAM_3d with specified model.")

    # Parse command-line arguments for experiment options
    parser.add_argument("--options_file", type=str, help="Specify the .json options file to use.")
    parser.add_argument("--experiment_id", type=str, help="Specify the experiment id to load options.", required=False)
    parser.add_argument("--dataset", type=str, help="Specify dataset (overwrites options file).", required=False)
    parser.add_argument("--cluster", type=str, help="Specify name of HPC cluster.", required=False, default="DTU_HPC")

    # Parse command-line arguments for LAM analysis
    parser.add_argument("--cube_no", type=str, required=False, default='001', help="ID of cube for LAM analysis")
    parser.add_argument("--h", type=int, required=False, default=28, help="Height of LAM ROI")
    parser.add_argument("--w", type=int, required=False, default=28, help="Width of LAM ROI")
    parser.add_argument("--d", type=int, required=False, default=28, help="Depth of LAM ROI")
    parser.add_argument("--window_size", type=int, required=False, default=8, help="Size of LAM ROI.")
    parser.add_argument("--use_new_cube_dir", type=int, required=False, default=1, help="use new cube directory")
    #parser.add_argument("--up_factor", default=1, type=int, required=False)

    args = parser.parse_args()

    return args


def main():

    # Returns None if no arguments parsed, as when run in IDE
    args = parse_LAM_arguments()

    # Define experiment parameters
    options_file = args.options_file
    experiment_id = args.experiment_id
    print("options_file", options_file)

    if experiment_id is not None:
        # Load saved options file saved based on specified experiment id
        print("Experiment_id", experiment_id)
        opt_path = load_options_from_experiment_id(experiment_id, root_dir=config.ROOT_DIR)

        # Load options
        opt = load_json(opt_path)
        #wandb_path = opt_path.rsplit("files", 1)[0]

    elif options_file is not None:
        # Load specified options file
        opt_path = os.path.join(config.ROOT_DIR, 'options', options_file)

        # Load options
        opt = load_json(opt_path)
        experiment_id = opt['experiment_id']

    else:
        # Load experiment options
        opt = parse_options(options_file)
        experiment_id = opt['experiment_id']

    # Set input type to 3D if not specified
    if 'input_type' not in opt:
        opt['input_type'] = '3D'

    # Define universal SR model using the KAIR define_Model framework
    from models.select_model import define_Model
    model = define_Model(opt)

    model.init_test(experiment_id)

    # Override seed for reproducibility, as LAM is sensitive to random initializations
    seed_value = 8339
    torch.manual_seed(seed_value)
    np.random.seed(seed_value)

    # Define parameters
    model_name = opt['model_architecture']
    cube_no = args.cube_no
    h = args.h
    w = args.w
    d = args.d
    window_size = args.window_size
    up_factor = opt['up_factor']
    input_size = opt['datasets']['patch_size']

    # %% Load test image
    if args.use_new_cube_dir:
        root_dir = config.ROOT_DIR
        lr_cube_dir = f"{root_dir}/saved_image_cubes/{opt['datasets']['name']}/LR_{opt['datasets']['degradation_type']}"
        hr_cube_dir = f"{root_dir}/saved_image_cubes/{opt['datasets']['name']}/HR_{opt['datasets']['degradation_type']}"
        img_lr = np.load(f"{lr_cube_dir}/cube_{input_size}_{cube_no}.npy")
        img_hr = np.load(f"{hr_cube_dir}/cube_{cube_no}.npy")
    else:
        img_lr = np.load(f"saved_image_cubes/{opt['datasets']['name']}_{up_factor}x/LR/cube_{input_size}_{cube_no}.npy")
        img_hr = np.load(f"saved_image_cubes/{opt['datasets']['name']}_{up_factor}x/HR/cube_{cube_no}.npy")
    tensor_lr = torch.from_numpy(img_lr) ; tensor_hr = torch.from_numpy(img_hr)
    cv2_lr = np.moveaxis(tensor_lr.numpy(), 0, 3) ; cv2_hr = np.moveaxis(tensor_hr.numpy(), 0, 3)

    print(img_hr.shape)
    print(img_lr.shape)

    # %% Show image
    if model_name == "MTVNet":
        lr_pred_area = opt['netG']['context_sizes'][-1]
        z_idx_lr = (2 * d + window_size) // (2 * up_factor) + (input_size - lr_pred_area) // 2
    else:
        z_idx_lr = d // up_factor + window_size // (2 * up_factor)
    z_idx_hr = d+window_size//2
    plt.imshow(cv2_hr[:,:,d+window_size//2,:],cmap='gray')
    plt.imshow(cv2_lr[:,:,z_idx_lr,:],cmap='gray')

    # %% Draw rectangle on slice
    pil_hr = Image.fromarray((img_hr[0,:,:,z_idx_hr] * 255).astype(np.uint8))
    pil_lr = Image.fromarray((img_lr[0,:,:,z_idx_lr] * 255).astype(np.uint8))
    draw_img_slice = pil_to_cv2(pil_hr)
    cv2.rectangle(draw_img_slice, (w, h), (w + window_size, h + window_size), (0, 0, 255), 1)
    position_pil = cv2_to_pil(draw_img_slice)

    if opt['input_type'] == "2D":
        # %% Calculate LAM 2D
        sigma = 1.2 ; fold = 50 ; l = 9 ; alpha = 0.1
        attr_objective = attribution_objective_2d(attr_grad_2d, h, w, window=window_size)
        gaus_blur_path_func = GaussianBlurPath_2d(sigma, fold, l)
        interpolated_grad_numpy, result_numpy, interpolated_numpy = Path_gradient_2d(tensor_lr[:,:,z_idx_lr].numpy(), model.netG, attr_objective, gaus_blur_path_func, cuda=True)
        grad_numpy, result = saliency_map(interpolated_grad_numpy, result_numpy)
        abs_normed_grad_numpy = grad_abs_norm_2d(grad_numpy)

        saliency_image_abs = vis_saliency(abs_normed_grad_numpy, zoomin=up_factor)
        angn_mean = abs_normed_grad_numpy #np.mean(abs_normed_grad_numpy,axis=2)
        angn_mean = (angn_mean - np.min(angn_mean)) / (np.max(angn_mean) - np.min(angn_mean))
        saliency_image_abs_mean = vis_saliency(angn_mean, zoomin=up_factor)
        blend_abs_and_hr = cv2_to_pil(pil_to_cv2(saliency_image_abs) * (1.0 - alpha) + pil_to_cv2(pil_hr) * alpha)

        gini_index = gini(abs_normed_grad_numpy)

    else:
        # %% Calculate LAM
        sigma = 1.2 ; fold = 50 ; l = 9 ; alpha = 0.1
        attr_objective = attribution_objective(attr_grad, h, w, d, window=window_size)
        gaus_blur_path_func = GaussianBlurPath(sigma, fold, l)
        if model_name == "ArSSR":
            xyz_hr = make_coord(list(tensor_hr.shape[1:])).unsqueeze(0)
            interpolated_grad_numpy, result_numpy, interpolated_numpy = Path_gradient_ArSSR(tensor_lr.numpy(), xyz_hr, model.netG, attr_objective, gaus_blur_path_func, cuda=True)
        else:
            interpolated_grad_numpy, result_numpy, interpolated_numpy = Path_gradient(tensor_lr.numpy(), model.netG, attr_objective, gaus_blur_path_func, cuda=True)
        grad_numpy, result = saliency_map(interpolated_grad_numpy, result_numpy)
        abs_normed_grad_numpy = grad_abs_norm(grad_numpy)
        grad_mag_sum = abs_normed_grad_numpy[:, :, z_idx_lr].sum()
        grad_mag_sum_roi = grad_mag_sum
        print("Absolute gradient magnitude over full input:", grad_mag_sum)


        # %% Make visualizations
        if model_name == "MTVNet" and (opt['netG']['num_levels'] > 1):
            crop_idx = (input_size - lr_pred_area) // 2
            grad_mag_sum_roi = abs_normed_grad_numpy[crop_idx:-crop_idx, crop_idx:-crop_idx, z_idx_lr].sum()
            print("Absolute gradient magnitude over SR ROI:", grad_mag_sum_roi)
            result_im = Image.fromarray((result[0, 0, :, :, z_idx_hr] * 255).astype(np.uint8))
            saliency_image_abs = vis_saliency(abs_normed_grad_numpy[crop_idx:-crop_idx, crop_idx:-crop_idx, z_idx_lr], zoomin=1)
            angn_mean = np.mean(abs_normed_grad_numpy[crop_idx:-crop_idx, crop_idx:-crop_idx, crop_idx:-crop_idx], axis=2)
            angn_mean = (angn_mean - np.min(angn_mean)) / (np.max(angn_mean) - np.min(angn_mean))
            saliency_image_abs_mean = vis_saliency(angn_mean, zoomin=1)
            saliency_image_abs_zoom = vis_saliency(abs_normed_grad_numpy[crop_idx:-crop_idx, crop_idx:-crop_idx, z_idx_lr], zoomin=4)
            blend_abs_and_sr = cv2_to_pil(pil_to_cv2(saliency_image_abs_zoom) * (1.0 - alpha) + pil_to_cv2(result_im) * alpha)
            print("Shape of pil_hr", pil_hr.size)
            print("Shape of saliency_image_abs_zoom", saliency_image_abs_zoom.size)
            blend_abs_and_hr = cv2_to_pil(pil_to_cv2(saliency_image_abs_zoom) * (1.0 - alpha) + pil_to_cv2(pil_hr) * alpha)

            gini_index = gini(abs_normed_grad_numpy[crop_idx:-crop_idx, crop_idx:-crop_idx, z_idx_lr])
        else:
            saliency_image_abs = vis_saliency(abs_normed_grad_numpy[:,:,z_idx_lr], zoomin=up_factor)
            angn_mean = np.mean(abs_normed_grad_numpy,axis=2)
            angn_mean = (angn_mean - np.min(angn_mean)) / (np.max(angn_mean) - np.min(angn_mean))
            saliency_image_abs_mean = vis_saliency(angn_mean, zoomin=up_factor)
            blend_abs_and_hr = cv2_to_pil(pil_to_cv2(saliency_image_abs) * (1.0 - alpha) + pil_to_cv2(pil_hr) * alpha)

            gini_index = gini(abs_normed_grad_numpy[:, :, z_idx_lr])

    diffusion_index = (1 - gini_index) * 100
    print(f"The DI of this case is {diffusion_index}")

    gini_index_mean = gini(angn_mean)
    diffusion_index_mean = (1 - gini_index_mean) * 100
    print(f"The DI_mean of this case is {diffusion_index_mean}")

    # %% Show LAM
    fig, axs = plt.subplots(1,3,figsize=(14,4))
    axs[0].imshow(position_pil)
    axs[1].imshow(saliency_image_abs)
    axs[2].imshow(saliency_image_abs_mean)

    # %% Save results
    cube_dir = f"{opt['datasets']['name']}_cube_{cube_no}_win{window_size}_h{h}-w{w}-d{d}"
    if args.use_new_cube_dir:
        cube_dir = cube_dir + "_new"
    if not os.path.exists("Results/" + cube_dir):
        os.makedirs("Results/" + cube_dir, exist_ok=True)
        os.makedirs("Results/" + cube_dir + "/lam_out", exist_ok=True)

    np.save(f'Results/{cube_dir}/lam_out/angn_{model_name}_{experiment_id}_{cube_dir}.npy',abs_normed_grad_numpy)

    plt.figure()
    plt.imshow(position_pil)
    plt.axis('off')
    plt.savefig(f'Results/{cube_dir}/selection_{cube_no}_h{h}-w{w}-d{d}.png', bbox_inches='tight', pad_inches=0)

    plt.figure()
    plt.imshow(saliency_image_abs)
    plt.axis('off')
    plt.savefig(f'Results/{cube_dir}/{model_name}_{experiment_id}_{cube_no}_h{h}-w{w}-d{d}.png', bbox_inches='tight', pad_inches=0)

    plt.figure()
    plt.imshow(saliency_image_abs_mean)
    plt.axis('off')
    plt.savefig(f'Results/{cube_dir}/{model_name}_{experiment_id}_{cube_no}_h{h}-w{w}-d{d}_mean.png', bbox_inches='tight', pad_inches=0)

    plt.figure()
    plt.imshow(blend_abs_and_hr)
    plt.axis('off')
    plt.savefig(f'Results/{cube_dir}/{model_name}_{experiment_id}_{cube_no}_h{h}-w{w}-d{d}_overlay.png', bbox_inches='tight', pad_inches=0)

    # %% Write to file
    with open(f'Results/{cube_dir}/LAM_DI.txt', 'a') as f:
        f.write(f'Diffusion index for {model_name}, {experiment_id}: {diffusion_index} ({cube_no}; selection: h{h}-w{w}-d{d})\n')
        f.write(f'Diffusion index (MEAN) for {model_name}, {experiment_id}: {diffusion_index_mean} ({cube_no}; selection: h{h}-w{w}-d{d})\n')
        f.write(f'Gradient magnitude sum over full input for {model_name}, {experiment_id}: {grad_mag_sum} ({cube_no}; selection: h{h}-w{w}-d{d})\n')
        f.write(f'Gradient magnitude sum over SR ROI for {model_name}, {experiment_id}: {grad_mag_sum_roi} ({cube_no}; selection: h{h}-w{w}-d{d})\n')

    # %%


if __name__ == '__main__':
    main()
