
{
  "task": "superresolution",
  "model": "plain",
  "model_architecture": "mDCSRN",

  // WandB parameters
  "wandb_mode": "online",
  "wandb_entity": "aulho",
  "wandb_project": "Benchmark_V2.0_4x_KIRBY21", // "Xtreme-CT_2x_SR_IXI"
  "experiment_id": "mDCSRN_ps32_4x_ID000282_L1_100K",
  "run_name": "mDCSRN_KIRBY21_ps32_4x",
  "note": "Dataset: KIRBY21 w. DivisiblePad k=2, Model: SuperFormer, patch size: 32. Batch size 4, pixelshuffle3D, accumulation steps: 1, iterations: 100K, Losses: L1, learning rate: 2e-4",

  "is_train": true,

  "gpu_ids": [0],
  "dist": false,
  "up_factor": 4,  // upscaling factor

  "save_model": true,  // flag to save model
  "save_time": 36,  // Backup save of model after 35 hours

  "path": {
    "root": "superresolution",
    "pretrained_netG_experiment_id": null, // "AugustNet_ps48_2x_ID000214"
    "pretrained_netE": null,
    "pretrained_optimizerG_experiment_id": null
  },

  "datasets": {
      "name": "KIRBY21",  // "TEST_DATASET" "Synthetic_2022_QIM_52_Bone" "2022_QIM_52_Bone" "IXI" "HCP_1200" "KIRBY21" "BRATS2023" "2022_QIM_52_Bone_Block",
      "dataset_type": "CacheDataset",   // "MonaiDataset" "MonaiSmartCacheDataset" "MonaiIterableDataset" "MonaiCacheDataset"

      "n_channels": 1,  // number of input channels of data samples
      "patch_size": 32,  // Low-resolution patch size. High-resolution has size LR*UP_FACTOR
      "channel_dim": "no_channel", // "no_channel", 0, 1, 2, 3. For instance: TEST_DATASET: -1, HCP_1200: "no_channel", IXI: "no_channel", BRATS2023: "no_channel"

      "norm_type": "scale_intensity", // "scale_intensity" "znormalization"
      "crop_type": "random_spatial", // "random_spatial" "random_label" "crop_pos_neg_label"

      "degradation_type": "resize",  // "kspace_trunc" "resize"
      "downsampling_method": "linear",  // used when degradation type is "resize"
      "blur_method": "3d_gaussian_blur",  // method for blurring, either "monai_gaussian_blur" or "3d_gaussian_blur"
      "blur_sigma": 1.0,  // std of gaussian kernel used for blurring before downsampling

      "factor_truncate": 4.0,  // Used when degradation type is "kspace_trunc"
      "norm_val": null,  // should usually be null, which means kspace truncation will divide by the max of each patch (unless max is very small)
      "slice_dim": 1,  // Should be changed if the dataset changes, HCP has slice_dim = 1, IXI has slice_dim = 3.
      "kspace_trunc_keep_shape": false,

    "train": {
      "dataset_params": {  // Used for MonaiSmartCacheDataset
        "patches_per_batch": 1,  // number of patches to sample for each batch
        "replace_rate": 0.10,
        "cache_num": 2000,
        "init_workers": 5,
        "replace_workers": 5
      },

      "dataloader_params": {  // Used for MonaiDataset
        "dataloader_shuffle": false,
        "dataloader_batch_size": 4, // Defines how many input images to sample patches from: usually 1. Superformer uses 4
        "num_load_workers": 2,
        "persist_workers": false,
        "pin_memory": false
      },

      "split": "train"
    },

    "test": {
      "dataset_params": {  // Used for MonaiSmartCacheDataset
        "patches_per_batch": 1,  // number of patches to sample for each batch
        "replace_rate": 0.10,
        "cache_num": 2000,
        "init_workers": 5,
        "replace_workers": 5
      },

      "dataloader_params": {  // Used for MonaiDataset
        "dataloader_shuffle": false,
        "dataloader_batch_size": 4, // Defines how many input images to sample patches from: usually 1
        "num_load_workers": 2,
        "persist_workers": false,
        "pin_memory": false
      },

      "split": "test"
    }
  },
  "netG": {
    "net_type": "mDCSRN",
    "description": "Multi-Level Densely Connected Network from mDCSRN-GAN paper",
    "in_channels": 1,
    "k_factor": 12,
    "k_size": 3,
    "num_dense_blocks": 8, // 8 used for ID000150 4x
    "num_dense_units": 4, // not working for larger values than 4
    "upsample_method": "pixelshuffle3D", // "deconv_nn_resize" "pixelshuffle3D" "Monaipixelshuffle" "nearest" // deconv_nn_resize used for ID000150 4x
    "use_checkpoint": false,

    "init_type": "default",
    "init_bn_type": "uniform",      // "uniform" | "constant"
    "init_gain": 0.2
  },

  "train": {

    "iterations": 100000,
    "validation_iterations": 500,   // number of iterations in each validation loop
    "epochs": 0,  // Maximum number of epochs
    "mixed_precision": null, // BF16", // "BF16",

    "num_accum_steps_G": 1,   // number of gradient accumulation steps on G

    "early_stop_patience": 4,  // validation loops to wait until validation loss decreases.

    "G_loss_weights": {
      "MSE": 0,
      "L1": 1.0, // 0.1
      "BCE_Logistic": 0,
      "BCE": 0,
      "VGG": 0,
      "VGG3D": 0,  // 0.006 0.003
      "GRAD": 0,
      "LAPLACE": 0,
      "TV3D": 0,  // 0.1
      "TEXTURE3D": 0,  // 0.5
      "ADV": 0,  // 10**-3,  // is 0.1 in mDCSRN-GAN paper, but uses WGAN-GP instead of vanilla GAN
      "STRUCTURE_TENSOR": 0  // 10**-7
    },

    "E_decay": 0,

    "G_optimizer_type": "adam",
    "G_optimizer_lr": 1e-4, // 2e-4, 5e-5
    "G_optimizer_wd": 0,

    "G_optimizer_clipgrad": 15,
    "G_optimizer_reuse": true,
    "G_scheduler_type": "MultiStepLR",
    "G_scheduler_milestones": [
      50000,  
      70000,   
      85000,
      95000   
    ], // 50000 70000 85000 95000 for 100K iterations 

    "G_scheduler_gamma": 0.5,
    "G_regularizer_orthstep": null,
    "G_regularizer_clipstep": null,

    "G_param_strict": true,
    "E_param_strict": true,

    "manual_seed": 8338,
    "checkpoint_test": 2500,
    "checkpoint_save": 1000000,
    "checkpoint_print": 2500,
    "checkpoint_save_visuals": 2500
  },
  "test": {
    "performance_metrics": ["psnr", "ssim", "nrmse"], // ["psnr", "ssim", "nrmse"],
    "upscaling_methods": ["tio_nearest", "tio_bspline"] // "tio_linear"
  }
}
