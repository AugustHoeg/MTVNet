
{
  "task": "superresolution",
  "model": "implicit",
  "model_architecture": "ArSSR",

  // WandB parameters
  "wandb_mode": "online",
  "wandb_entity": "aulho",
  "wandb_project": "Xtreme-CT",
  "experiment_id": "debug_home_ID000005",
  "run_name": "ArSSR_test_",
  "note": "Enter note about experiment here",

  "is_train": true,

  "gpu_ids": [0],
  "dist": false,
  "up_factor": 2,  // upscaling factor

  "save_model": true,  // flag to save model
  "save_time": 35,  // Backup save of model after 35 hours

  "path": {
    "root": "superresolution",
    "pretrained_netG_experiment_id": null, // "debug_home_ID000005",
    "pretrained_netE": null,
    "pretrained_optimizerG_experiment_id": null
  },

  "datasets": {
      "name": "IXI",  // "TEST_DATASET" "2022_QIM_52_Bone" "IXI" "HCP_1200" "KIRBY21" "BRATS2023" "2022_QIM_52_Bone_Block",
      "dataset_type": "MonaiSmartCacheDataset",   // "MonaiDataset" "MonaiSmartCacheDataset" "MonaiIterableDataset" "MonaiCacheDataset" "MasterThesisDataset"

      "n_channels": 1,  // number of input channels of data samples
      "patch_size": 40,  // Low-resolution patch size. High-resolution has size LR*UP_FACTOR
      "channel_dim": "no_channel", // "no_channel", 0, 1, 2, 3. For instance: TEST_DATASET: -1, HCP_1200: "no_channel"

      "norm_type": "scale_intensity", // "scale_intensity" "znormalization"
      "crop_type": "random_label", // "random_spatial" "random_label". Bone dataset should use: "random_label"

      "degradation_type": "resize",  // "kspace_trunc" "resize"
      "downsampling_method": "linear",  // used when degradation type is "resize"
      "blur_method": "monai_gaussian_blur",  // method for blurring, either "monai_gaussian_blur" or "3d_gaussian_blur"
      "blur_sigma": 1.0,  // std of gaussian kernel used for blurring before downsampling

      "factor_truncate": 4.0,  // Used when degradation type is "kspace_trunc"
      "norm_val": null,  // should usually be null, which means kspace truncation will divide by the max of each patch (unless max is very small)
      "slice_dim": 1,  // Should be changed if the dataset changes, HCP has slice_dim = 1, IXI has slice_dim = 3.
      "kspace_trunc_keep_shape": false,

    "train": {
      "dataset_params": {  // Used for MonaiSmartCacheDataset
        "patches_per_batch": 1,  // number of patches to sample for each batch
        "replace_rate": 0.10,
        "cache_num": 20,
        "init_workers": 5,
        "replace_workers": 5
      },

      "dataloader_params": {  // Used for MonaiDataset
        "dataloader_shuffle": false,
        "dataloader_batch_size": 2,
        "num_load_workers": 0,
        "persist_workers": false,
        "pin_memory": false
      },

      "split": "train"
    },

    "test": {
      "dataset_params": {  // Used for MonaiSmartCacheDataset
        "patches_per_batch": 1,  // number of patches to sample for each batch
        "replace_rate": 0.10,
        "cache_num": 10,
        "init_workers": 5,
        "replace_workers": 5
      },

      "dataloader_params": {  // Used for MonaiDataset
        "dataloader_shuffle": true,
        "dataloader_batch_size": 2,
        "num_load_workers": 0,
        "persist_workers": false,
        "pin_memory": false
      },

      "split": "test"
    }
  },
  "netG": {
    "net_type": "ArSSR",
    "description": "Implicit SR model ArSSR",
    "decoder_depth" : 8,
    "decoder_width" : 256,
    "feature_dim" : 128,
    "encoder_name" : "SRResNet",

    "init_type": "kaiming_normal",
    "init_bn_type": "uniform",      // "uniform" | "constant"
    "init_gain": 0.2
  },

  "train": {

    "epochs": 50,  // Maximum number of epochs
    "mixed_precision": "BF16", // FP32, BF16, FP16

    "num_accum_steps_G": 3,   // number of gradient accumulation steps on G

    "G_loss_weights": {
      "MSE": 0,
      "L1": 1.0,
      "BCE_Logistic": 0,
      "BCE": 0,
      "VGG": 0,
      "VGG3D": 0, // 0.006,
      "GRAD": 0,
      "LAPLACE": 0,
      "TV3D": 0,  // 0.1
      "TEXTURE3D": 0,  // 0.5
      "ADV": 0,  // 10**-3 = 10e-4 for master thesis,  // is 0.1 in mDCSRN-GAN paper, but uses WGAN-GP instead of vanilla GAN
      "STRUCTURE_TENSOR": 0  // 10**-7
    },

    "E_decay": 0,

    "G_optimizer_type": "adam",
    "G_optimizer_lr": 1e-4, // 1e-4, 2e-4,
    "G_optimizer_wd": 0,

    "G_optimizer_clipgrad": 15,  // 15, 10
    "G_optimizer_reuse": true,
    "G_scheduler_type": "MultiStepLR",
    "G_scheduler_milestones": [
      250000,
      400000,
      450000,
      475000,
      500000
    ],

    "G_scheduler_gamma": 0.5,
    "G_regularizer_orthstep": null,
    "G_regularizer_clipstep": null,

    "G_param_strict": true, // true
    "E_param_strict": true,

    "manual_seed": 8329,
    "checkpoint_test": 0,
    "checkpoint_save": 1000000,
    "checkpoint_print": 0,
    "checkpoint_save_visuals": 0
  },
  "test": {
    "performance_metrics": ["psnr", "ssim", "nrmse"],
    "upscaling_methods": ["tio_nearest", "tio_bspline"]  // "tio_linear"
  }
}
